[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Problemas de Inferencia Estadística",
    "section": "",
    "text": "Prefacio\nEste manual de soluciones complementa el libro Inferencia Estadística y está diseñado para proporcionar un apoyo integral al proceso de aprendizaje. Cada solución ha sido desarrollada con el mismo rigor teórico-práctico que caracteriza al curso, ofreciendo no solo la respuesta correcta, sino también el razonamiento estadístico y la interpretación práctica necesarios para una comprensión profunda.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#filosofía-pedagógica",
    "href": "index.html#filosofía-pedagógica",
    "title": "Problemas de Inferencia Estadística",
    "section": "Filosofía pedagógica",
    "text": "Filosofía pedagógica\nAl igual que el libro principal, este manual sigue un enfoque “teórico-práctico” sin concesiones. Las soluciones están diseñadas para:\n\nReforzar la comprensión de los conceptos fundamentales mediante aplicaciones concretas\nDesarrollar la intuición estadística a través de interpretaciones razonadas\n\nConectar la teoría con la práctica mediante código R completamente funcional\nFomentar el pensamiento crítico sobre las limitaciones y supuestos de cada método",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#cómo-usar-este-manual",
    "href": "index.html#cómo-usar-este-manual",
    "title": "Problemas de Inferencia Estadística",
    "section": "¿Cómo usar este manual?",
    "text": "¿Cómo usar este manual?\nPara maximizar el beneficio de este recurso:\n\nIntentar primero: Resuelve cada ejercicio por tu cuenta antes de consultar la solución\nEstudiar el proceso: No solo copies el código, entiende la lógica detrás de cada paso\n\nExperimentar: Modifica los parámetros y observa cómo cambian los resultados\nReflexionar: Considera las implicaciones prácticas de cada resultado obtenido",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#metodología-de-las-soluciones",
    "href": "index.html#metodología-de-las-soluciones",
    "title": "Problemas de Inferencia Estadística",
    "section": "Metodología de las soluciones",
    "text": "Metodología de las soluciones\nCada solución incluye:\n\nCódigo R completo: Totalmente ejecutable y comentado\nExplicaciones paso a paso: Qué hace cada línea y por qué\nInterpretación de resultados: Qué significan los números obtenidos\nGráficos explicativos: Visualización de conceptos clave\nConsejos prácticos: Cuándo y cómo usar cada técnica\n\n\n\n\n\n\n\nImportanteUso responsable\n\n\n\nEste manual es una herramienta de aprendizaje, no un sustituto del pensamiento propio. Utilízalo para verificar tu comprensión y mejorar tu técnica, pero siempre tras haber hecho un esfuerzo genuino por resolver los problemas de forma independiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-de-software",
    "href": "index.html#requisitos-de-software",
    "title": "Problemas de Inferencia Estadística",
    "section": "Requisitos de software",
    "text": "Requisitos de software\nPara ejecutar las soluciones necesitas tener instalados los siguientes paquetes de R:\n# Paquetes principales\ninstall.packages(c(\n  \"car\",           # Diagnósticos avanzados\n  \"MASS\",          # Datasets y funciones estadísticas  \n  \"glmnet\",        # Regularización\n  \"caret\",         # Machine learning\n  \"pROC\",          # Curvas ROC\n  \"fitdistrplus\",  # Ajuste de distribuciones\n  \"lmtest\"         # Tests estadísticos\n))\n\n\n\n\n\n\nNotaSobre los autores\n\n\n\nVíctor Aceña Gil es graduado en Matemáticas por la UNED, máster en Tratamiento Estadístico y Computacional de la Información por la UCM y la UPM, doctor en Tecnologías de la Información y las Comunicaciones por la URJC y profesor del departamento de Informática y Estadística de la URJC. Miembro del grupo de investigación de alto rendimiento en Fundamentos y Aplicaciones de la Ciencia de Datos, DSLAB, de la URJC. Pertenece al grupo de innovación docente, DSLAB-TI.\nIsaac Martín de Diego es diplomado en Estadística por la Universidad de Valladolid (UVA), licenciado en Ciencias y Técnicas Estadísticas por la Universidad Carlos III de Madrid (UC3M), doctor en Ingeniería Matemática por la UC3M, catedrático de Ciencias de la Computación e Inteligencia Artificial del departamento de Informática y Estadística de la URJC. Es fundador y coordinador del DSLAB y del DSLAB-TI.\n\n\nEsta obra está bajo una licencia de Creative Commons Atribución-CompartirIgual 4.0 Internacional.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "tema0_intro_solucion.html",
    "href": "tema0_intro_solucion.html",
    "title": "1  Ejercicio 1",
    "section": "",
    "text": "Pregunta: Describe en tus propias palabras qué es la Ciencia de Datos y su importancia en el análisis de grandes volúmenes de datos.\nSolución: La Ciencia de Datos es una disciplina interdisciplinaria que se centra en la extracción de conocimiento significativo a partir de grandes conjuntos de datos. Es crucial en un mundo impulsado por los datos, ya que permite tomar decisiones informadas y hacer predicciones basadas en el análisis de datos. La Ciencia de Datos combina elementos de estadística, informática y conocimiento específico del dominio para interpretar datos y aplicar este conocimiento en diversas áreas como la medicina, las finanzas y la tecnología. Su importancia radica en su capacidad para transformar datos crudos en información valiosa que puede impulsar la innovación y la eficiencia en múltiples campos.\n\n2 Ejercicio 2\nPregunta: Enumera las herramientas estadísticas que se utilizan en la inferencia estadística y explica brevemente su propósito.\nSolución: En la inferencia estadística, se utilizan diversas herramientas para analizar datos y hacer generalizaciones sobre una población a partir de muestras:\n\nPruebas de Hipótesis: Se utilizan para determinar si existe suficiente evidencia en una muestra de datos para inferir que una cierta condición es verdadera para toda la población.\nIntervalos de Confianza: Proporcionan un rango estimado que es probable que contenga el valor de un parámetro desconocido de la población, con un cierto nivel de confianza.\nAnálisis de Varianza (ANOVA): Permite comparar tres o más medias de grupos para determinar si al menos una de las medias es diferente de las demás.\nChi-cuadrado (χ²): Es una prueba que mide la discrepancia entre los datos observados y los datos que se esperarían según un modelo específico.\nT-test: Evalúa si las medias de dos grupos son estadísticamente diferentes entre sí.\nCorrelación: Mide la relación entre dos variables y la fuerza de esta relación.\nEstadística Bayesiana: Utiliza la probabilidad para representar la incertidumbre sobre los parámetros del modelo y actualiza esta incertidumbre a medida que se obtienen más datos.\nMétodos de Muestreo: Incluyen técnicas para seleccionar muestras representativas de la población para realizar inferencias estadísticas.\nMétodos No Paramétricos: Son técnicas que no asumen una distribución específica de los datos y son útiles cuando no se cumplen los supuestos de los métodos paramétricos.\n\n\n\n3 Ejercicio 3\nPregunta: Define los términos “población” y “muestra” y explica la diferencia entre ambos.\nSolución:\n\nPoblación: Se refiere al conjunto completo de elementos o resultados que se están estudiando, del cual se desean obtener conclusiones. La población incluye a todos los individuos, mediciones, objetos o eventos que cumplen con un conjunto de especificaciones previamente definidas. Por ejemplo, si estamos estudiando la altura de los estudiantes de una universidad, la población sería la altura de todos los estudiantes de esa universidad.\nMuestra: Es un subconjunto de la población que se selecciona para representarla. La muestra debe ser representativa de la población para que las inferencias hechas a partir de ella sean válidas. Por ejemplo, si elegimos a 100 estudiantes al azar de la universidad mencionada anteriormente, esos 100 estudiantes constituirían una muestra de la población.\n\nLa diferencia principal entre ambos términos es el alcance. Mientras que la población es el grupo completo que se quiere estudiar, la muestra es solo una parte de ese grupo. Las muestras se utilizan porque a menudo es impracticable o imposible estudiar toda la población debido a limitaciones de tiempo, costo o logística. Por lo tanto, se selecciona una muestra para obtener estimaciones o pruebas sobre la población completa.\n\n\n4 Ejercicio 4\nPregunta: ¿Qué es una distribución de probabilidad y cómo se relaciona con las variables cualitativas y cuantitativas?\nSolución: Una distribución de probabilidad es una función matemática que describe la probabilidad de ocurrencia de los diferentes posibles resultados en un experimento. En otras palabras, asigna probabilidades a cada posible resultado de una variable aleatoria. Las distribuciones de probabilidad se relacionan con las variables cualitativas y cuantitativas de la siguiente manera:\n\nVariables Cualitativas (o Categóricas): Son aquellas que describen una cualidad o categoría y no tienen un orden o medida numérica inherente. Las distribuciones de probabilidad para estas variables son conocidas como distribuciones discretas y asignan probabilidades a resultados específicos. Un ejemplo es la distribución binomial, que puede modelar eventos como el lanzamiento de una moneda, donde los resultados son categóricos (cara o cruz).\nVariables Cuantitativas: Son variables que se pueden medir en una escala numérica y tienen sentido hablar de valores mayores o menores. Las distribuciones de probabilidad asociadas a estas variables son distribuciones continuas y asignan probabilidades a intervalos de números. Por ejemplo, la distribución normal es una distribución continua que se utiliza comúnmente para modelar fenómenos naturales como la altura o el peso de individuos.\n\n\n\n5 Ejercicio 5\nPregunta: Realiza un resumen descriptivo de un conjunto de datos utilizando medidas de tendencia central y dispersión.\nSolución: Imaginemos un conjunto de datos que representa las calificaciones de un grupo de estudiantes en un examen:\n\ndatos=c(72, 85, 90, 68, 88, 76, 95, 89, 75, 80)\ndatos\n\n [1] 72 85 90 68 88 76 95 89 75 80\n\n\nMedia: \\[\n   \\text{Media} = \\frac{72 + 85 + 90 + 68 + 88 + 76 + 95 + 89 + 75 + 80}{10} = \\frac{818}{10} = 81.8\n   \\]\nMediana: Ordenamos los datos: 68, 72, 75, 76, 80, 85, 88, 89, 90, 95. Como hay 10 valores, la mediana es el promedio de los dos valores centrales: \\[\n   \\text{Mediana} = \\frac{80 + 85}{2} = \\frac{165}{2} = 82.5\n   \\]\nModa: No hay un valor que se repita más de una vez, por lo que no hay moda en este conjunto de datos.\nRango: \\[\n   \\text{Rango} = 95 - 68 = 27\n   \\]\nVarianza: Primero, calculamos la media de los cuadrados de las desviaciones respecto a la media: \\[\n   \\sigma^2 = \\frac{(72-81.8)^2 + (85-81.8)^2 + \\ldots + (80-81.8)^2}{10} = 71.4\n   \\]\nDesviación Estándar: \\[\n   \\sigma = \\sqrt{71.4} \\approx 8.45\n   \\]\nCuartiles: - Primer Cuartil (Q1): Valor en el percentil 25 (primera mitad inferior de los datos): \\[\n     Q1 = 75\n     \\] - Tercer Cuartil (Q3): Valor en el percentil 75 (primera mitad superior de los datos): \\[\n     Q3 = 89\n     \\]\nResumen Descriptivo\n\nMedia: 81.8\nMediana: 82.5\nModa: No hay moda\nRango: 27\nVarianza: 71.4\nDesviación Estándar: 8.45\nPrimer Cuartil (Q1): 75\nTercer Cuartil (Q3): 89\n\nEste resumen descriptivo proporciona una visión clara y concisa de las características principales del conjunto de datos, permitiendo una mejor comprensión de su distribución y variabilidad.\n\n\n6 Ejercicio 6\nPregunta: Explica la diferencia entre estadística descriptiva e inferencial y proporciona un ejemplo de cómo se utiliza cada una.\nSolución: La estadística descriptiva y la estadística inferencial son dos ramas principales de la estadística que tienen propósitos y métodos diferentes:\n\nEstadística Descriptiva: Se centra en resumir y describir las características de un conjunto de datos. Utiliza medidas como la media, mediana, moda, rango y desviación estándar para dar una visión general de los datos. Por ejemplo, si tenemos los resultados de una prueba de matemáticas de una clase, la estadística descriptiva podría incluir el cálculo de la media de las calificaciones, la calificación más alta, la más baja y la variabilidad de las calificaciones.\nEstadística Inferencial: Va más allá de la descripción de los datos y busca hacer predicciones o generalizaciones sobre una población basándose en una muestra de datos. Utiliza herramientas como pruebas de hipótesis, intervalos de confianza y regresión para inferir patrones y tomar decisiones. Por ejemplo, si queremos saber si un nuevo método de enseñanza es efectivo, podríamos aplicarlo a una muestra de estudiantes y usar la estadística inferencial para determinar si los resultados observados en la muestra pueden generalizarse a todos los estudiantes.\n\nSolución:\n\n\n7 Ejercicio 7\nPregunta: Diseña un experimento para ilustrar cómo el muestreo aleatorio simple puede ser utilizado para estimar una característica de una población.\nSolución: Para ilustrar cómo el muestreo aleatorio simple puede ser utilizado para estimar una característica de una población, consideremos el siguiente experimento:\nObjetivo del Experimento: Estimar la proporción de personas en una ciudad que prefieren el transporte público sobre otros medios de transporte.\nPoblación: Todos los residentes de la ciudad que son mayores de edad y utilizan algún medio de transporte para desplazarse.\nCaracterística de Interés: Preferencia por el transporte público.\nProcedimiento:\n\nDefinición de la Población: Identificar a todos los residentes de la ciudad que son mayores de edad y utilizan algún medio de transporte.\nSelección de la Muestra:\n\nUtilizar un registro actualizado de la población, como el padrón municipal, para obtener una lista de individuos.\nSeleccionar una muestra aleatoria de individuos utilizando un generador de números aleatorios.\nDeterminar el tamaño de la muestra necesario para obtener resultados con un nivel de confianza y un margen de error deseado.\n\nRecolección de Datos:\n\nContactar a los individuos seleccionados y preguntarles si prefieren el transporte público sobre otros medios de transporte.\nRegistrar las respuestas afirmativas y negativas.\n\nAnálisis de Datos:\n\nCalcular la proporción de respuestas afirmativas en la muestra.\nUtilizar esta proporción como una estimación puntual de la preferencia en la población total.\n\nEstimación de la Población:\n\nCalcular un intervalo de confianza para la proporción estimada, lo que proporcionará un rango dentro del cual se espera que se encuentre la verdadera proporción de la población con un cierto nivel de confianza.\n\nConclusión:\n\nPresentar la proporción estimada y el intervalo de confianza como la estimación de la preferencia por el transporte público en la población.\nDiscutir las limitaciones del estudio y la posibilidad de sesgo si la muestra no fue perfectamente aleatoria o si hubo una tasa de respuesta baja.\n\n\n\n\n8 Ejercicio 8\nPregunta: Explica el Teorema Central del Límite y su relevancia en la inferencia estadística.\nSolución: Teorema Central del Límite (TCL)\nEl Teorema Central del Límite es un principio fundamental en estadística que establece que, bajo ciertas condiciones, la distribución de la suma de un gran número de variables aleatorias independientes y identicamente distribuidas (i.i.d.) tiende a aproximarse a una distribución normal (gaussiana), independientemente de la forma de la distribución original de las variables.\nEnunciado del Teorema Central del Límite\nPara una muestra de tamaño ( n ) tomada de una población con cualquier distribución de probabilidad con media ( ) y desviación estándar ( ), la distribución de la media muestral \\(\\bar{X}\\) se aproximará a una distribución normal a medida que ( n ) se haga grande. Matemáticamente, si ( X_1, X_2, …, X_n ) son variables aleatorias independientes e idénticamente distribuidas con media ( ) y desviación estándar ( ), entonces la media muestral \\(\\bar{X}\\) se distribuye aproximadamente como:\n\\[\n\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\nImportancia y Relevancia en la Inferencia Estadística\n\nJustificación del Uso de la Distribución Normal: El TCL permite justificar el uso de la distribución normal en la inferencia estadística. Incluso si la población original no está distribuida normalmente, la distribución de las medias muestrales se aproximará a una distribución normal si el tamaño de la muestra es suficientemente grande.\nConstrucción de Intervalos de Confianza: Permite construir intervalos de confianza para estimar parámetros poblacionales. Por ejemplo, al estimar la media poblacional, podemos utilizar la distribución normal para determinar un rango donde probablemente se encuentra la media verdadera.\nPruebas de Hipótesis: Facilita la realización de pruebas de hipótesis. Dado que la distribución de la media muestral es aproximadamente normal, se pueden aplicar métodos estadísticos basados en la normalidad para decidir si rechazar o no una hipótesis nula.\nSimplificación de Cálculos: El TCL simplifica el análisis de datos, ya que permite trabajar con la distribución normal, que tiene propiedades bien definidas y es ampliamente comprendida y tabulada, facilitando los cálculos y la interpretación de los resultados.\nAplicación Universal: Es aplicable en una amplia gama de situaciones, desde la economía y la biología hasta la ingeniería y las ciencias sociales, siempre que se cumplan las condiciones necesarias (independencia y tamaño de muestra grande).\n\n\n\n9 Ejercicio 9\nPregunta: Compara y contrasta la estadística paramétrica y no paramétrica, dando ejemplos de cuándo se utilizaría cada una.\nSolución: La estadística paramétrica y la estadística no paramétrica son dos enfoques de análisis estadístico que tienen diferentes supuestos y aplicaciones. La estadística paramétrica se utiliza cuando los datos se ajustan a ciertos supuestos y se conoce la distribución subyacente, lo que permite hacer inferencias más precisas si estos supuestos se cumplen. Por otro lado, la estadística no paramétrica es más flexible y se puede utilizar en una variedad más amplia de situaciones, especialmente cuando los datos no cumplen con los supuestos de los métodos paramétricos.\n\nEstadística Paramétrica:\n\nSupuestos: Asume que los datos de la muestra provienen de una población que sigue una distribución de probabilidad conocida, generalmente la distribución normal. También asume homogeneidad de varianzas y la independencia de las observaciones.\nUso: Se utiliza cuando se conoce la forma de la distribución subyacente de los datos o cuando se tiene una muestra grande que, por el Teorema Central del Límite, tiende a una distribución normal.\nEjemplos de Herramientas: T-test, ANOVA, regresión lineal.\nEjemplo de Uso: Si queremos comparar las alturas promedio de dos grupos de personas y sabemos que las alturas siguen una distribución normal, podríamos usar un T-test paramétrico.\n\nEstadística No Paramétrica:\n\nSupuestos: No hace suposiciones sobre la forma de la distribución de la población. Es útil cuando no se cumplen los suposiciones de normalidad o cuando se trata con muestras pequeñas.\nUso: Se aplica en situaciones donde no se conoce la distribución de los datos o cuando los datos son ordinales o nominales.\nEjemplos de Herramientas: Test de Wilcoxon, Test de Kruskal-Wallis, Test de Chi-cuadrado.\nEjemplo de Uso: Si queremos comparar las medianas de los tiempos de respuesta de dos grupos en una prueba y los datos son claramente no normales o son rangos en lugar de medidas, podríamos usar un test de Wilcoxon no paramétrico.\n\n\n\n\n10 Ejercicio 10\nPregunta: Discute las diferencias entre los enfoques frecuentista y bayesiano en la inferencia estadística y da un ejemplo de aplicación para cada uno.\nSolución: La inferencia estadística se basa en métodos que nos permiten hacer conclusiones sobre una población a partir de datos muestrales. Existen dos enfoques principales en la inferencia estadística: el enfoque frecuentista y el enfoque bayesiano. A continuación, se presentan las diferencias clave entre estos enfoques y ejemplos de aplicación para cada uno.\nEnfoque Frecuentista\nCaracterísticas Principales:\n\nInterpretación de Probabilidad: La probabilidad se interpreta como la frecuencia relativa de eventos en el largo plazo. Es decir, si un experimento se repite infinitas veces, la probabilidad de un evento es la proporción de veces que ocurre.\nEstimación de Parámetros: Se basa en el concepto de estimación puntual y de intervalos de confianza. Los parámetros poblacionales se consideran fijos pero desconocidos, y los datos son aleatorios.\nPruebas de Hipótesis: Utiliza pruebas de hipótesis y valores p para decidir si rechazar la hipótesis nula. Las decisiones se basan en la frecuencia de observación de datos extremos bajo la suposición de que la hipótesis nula es verdadera.\nNo usa Información Priori: Los análisis frecuentistas no incorporan información previa sobre los parámetros; sólo se basan en los datos actuales.\n\nEjemplo de Aplicación Frecuentista:\nImaginemos que una empresa desea saber si un nuevo medicamento es efectivo para reducir la presión arterial. Realizan un ensayo clínico donde:\n\nHipótesis Nula (H0): El medicamento no tiene efecto en la presión arterial (la media de la reducción de la presión arterial es 0).\nHipótesis Alternativa (H1): El medicamento reduce la presión arterial (la media de la reducción de la presión arterial es mayor que 0).\n\nEl análisis frecuentista implicaría:\n\nRecoger datos muestrales de pacientes.\nCalcular la media y la desviación estándar de la reducción en la presión arterial.\nRealizar una prueba t para comparar la media muestral con 0.\nCalcular el valor p para determinar la significancia estadística.\nRechazar o no la hipótesis nula en función del valor p y el nivel de significancia establecido (por ejemplo, 0.05).\n\nEnfoque Bayesiano\nCaracterísticas Principales:\n\nInterpretación de Probabilidad: La probabilidad se interpreta como un grado de creencia o confianza sobre la ocurrencia de un evento, dado el conocimiento disponible.\nEstimación de Parámetros: Los parámetros poblacionales se tratan como variables aleatorias con distribuciones de probabilidad. Utiliza la distribución a priori (información previa) y los datos observados para obtener la distribución a posteriori.\nActualización de Conocimientos: Aplica el Teorema de Bayes para actualizar la probabilidad a medida que se dispone de nueva información.\nIncorporación de Información Priori: Utiliza información previa sobre los parámetros en forma de distribuciones a priori, que se combinan con la información de los datos para obtener las distribuciones a posteriori.\n\nEjemplo de Aplicación Bayesiana:\nSupongamos que un médico quiere estimar la probabilidad de que un paciente tenga una enfermedad dada, basándose en un resultado positivo de una prueba diagnóstica y en el conocimiento previo sobre la prevalencia de la enfermedad y la precisión de la prueba.\n\nInformación a Priori: El médico tiene una estimación previa (a priori) de la prevalencia de la enfermedad (por ejemplo, 1% de la población tiene la enfermedad).\nDatos Observados: La sensibilidad (probabilidad de un resultado positivo dado que el paciente tiene la enfermedad) es 90% y la especificidad (probabilidad de un resultado negativo dado que el paciente no tiene la enfermedad) es 95%.\nAplicación del Teorema de Bayes:\n\n( P(E|+)): Probabilidad de tener la enfermedad dado un resultado positivo.\n( P(+|E)): Sensibilidad.\n( P(+| E)): Probabilidad de un falso positivo (1 - especificidad).\n( P(E)): Prevalencia de la enfermedad.\n( P(E)): Probabilidad de no tener la enfermedad (1 - prevalencia).\n\n\n\\[\nP(E|+) = \\frac{P(+|E) \\cdot P(E)}{P(+|E) \\cdot P(E) + P(+| \\neg E) \\cdot P(\\neg E)}\n\\]\nSustituyendo los valores:\n\\[\nP(E|+) = \\frac{0.90 \\cdot 0.01}{0.90 \\cdot 0.01 + 0.05 \\cdot 0.99} = \\frac{0.009}{0.009 + 0.0495} = \\frac{0.009}{0.0585} \\approx 0.154\n\\]\nEl resultado indica que, dado un resultado positivo de la prueba, la probabilidad a posteriori de tener la enfermedad es aproximadamente 15.4%.\nConclusión\nFrecuentista:\n\nNo utiliza información previa.\nSe basa en la frecuencia de los eventos.\nAdecuado para análisis donde no se dispone de información previa o se quiere evitar la subjetividad.\n\nBayesiano:\n\nUtiliza información previa (a priori).\nActualiza las probabilidades a medida que se dispone de nueva información.\nAdecuado para situaciones donde la información previa es relevante y valiosa.\n\nAmbos enfoques son útiles y válidos, y la elección entre ellos depende del contexto del problema, la disponibilidad de información previa y las preferencias del investigador.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Ejercicio 1</span>"
    ]
  },
  {
    "objectID": "tema1_EDA1_solucion.html",
    "href": "tema1_EDA1_solucion.html",
    "title": "2  Cargar el conjunto de datos",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\n\n\nurl &lt;- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\"\ndownload.file(url, \"bank.zip\")\nunzip(\"bank.zip\", \"bank-full.csv\")\nbank_data &lt;- read.csv(\"bank-full.csv\",sep=\";\")\n\n\n# Pregunta 1: Estructura del DataFrame\nhead(bank_data)\n\n  age          job marital education default balance housing loan contact day\n1  58   management married  tertiary      no    2143     yes   no unknown   5\n2  44   technician  single secondary      no      29     yes   no unknown   5\n3  33 entrepreneur married secondary      no       2     yes  yes unknown   5\n4  47  blue-collar married   unknown      no    1506     yes   no unknown   5\n5  33      unknown  single   unknown      no       1      no   no unknown   5\n6  35   management married  tertiary      no     231     yes   no unknown   5\n  month duration campaign pdays previous poutcome  y\n1   may      261        1    -1        0  unknown no\n2   may      151        1    -1        0  unknown no\n3   may       76        1    -1        0  unknown no\n4   may       92        1    -1        0  unknown no\n5   may      198        1    -1        0  unknown no\n6   may      139        1    -1        0  unknown no\n\ndim(bank_data)\n\n[1] 45211    17\n\n\n\n# Pregunta 2: Resumen del DataFrame\nsummary(bank_data)\n\n      age            job              marital           education        \n Min.   :18.00   Length:45211       Length:45211       Length:45211      \n 1st Qu.:33.00   Class :character   Class :character   Class :character  \n Median :39.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :40.94                                                           \n 3rd Qu.:48.00                                                           \n Max.   :95.00                                                           \n   default             balance         housing              loan          \n Length:45211       Min.   : -8019   Length:45211       Length:45211      \n Class :character   1st Qu.:    72   Class :character   Class :character  \n Mode  :character   Median :   448   Mode  :character   Mode  :character  \n                    Mean   :  1362                                        \n                    3rd Qu.:  1428                                        \n                    Max.   :102127                                        \n   contact               day           month              duration     \n Length:45211       Min.   : 1.00   Length:45211       Min.   :   0.0  \n Class :character   1st Qu.: 8.00   Class :character   1st Qu.: 103.0  \n Mode  :character   Median :16.00   Mode  :character   Median : 180.0  \n                    Mean   :15.81                      Mean   : 258.2  \n                    3rd Qu.:21.00                      3rd Qu.: 319.0  \n                    Max.   :31.00                      Max.   :4918.0  \n    campaign          pdays          previous          poutcome        \n Min.   : 1.000   Min.   : -1.0   Min.   :  0.0000   Length:45211      \n 1st Qu.: 1.000   1st Qu.: -1.0   1st Qu.:  0.0000   Class :character  \n Median : 2.000   Median : -1.0   Median :  0.0000   Mode  :character  \n Mean   : 2.764   Mean   : 40.2   Mean   :  0.5803                     \n 3rd Qu.: 3.000   3rd Qu.: -1.0   3rd Qu.:  0.0000                     \n Max.   :63.000   Max.   :871.0   Max.   :275.0000                     \n      y            \n Length:45211      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n# Pregunta 3: Distribución de la Edad\nsummary(bank_data$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   33.00   39.00   40.94   48.00   95.00 \n\nggplot(bank_data, aes(x = age)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribución de la Edad de los Clientes\",\n       x = \"Edad\",\n       y = \"Frecuencia\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Pregunta 4: Balance Promedio\nmean(bank_data$balance, na.rm = TRUE)\n\n[1] 1362.272\n\nmean(bank_data$balance[bank_data$y == \"yes\"], na.rm = TRUE)\n\n[1] 1804.268\n\n\n\n# Pregunta 5: Frecuencia de Contacto\nsummary(bank_data$campaign)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   1.000   2.000   2.764   3.000  63.000 \n\n\n\n# Pregunta 6: Análisis de Duración\nsummary(bank_data$duration)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   103.0   180.0   258.2   319.0  4918.0 \n\nmean(bank_data$duration[bank_data$y == \"yes\"], na.rm = TRUE)\n\n[1] 537.2946\n\n\n\n# Pregunta 7: Relación entre Balance y Duración\nggplot(bank_data, aes(x = balance, y = duration)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relación entre Balance y Duración del Último Contacto\",\n       x = \"Balance\",\n       y = \"Duración (segundos)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Pregunta 8: Segmentación por Trabajo\nbank_data %&gt;% group_by(job) %&gt;%\n  summarise(media_balance = mean(balance, na.rm = TRUE),\n            mediana_balance = median(balance, na.rm = TRUE))\n\n# A tibble: 12 × 3\n   job           media_balance mediana_balance\n   &lt;chr&gt;                 &lt;dbl&gt;           &lt;dbl&gt;\n 1 admin.                1136.            396 \n 2 blue-collar           1079.            388 \n 3 entrepreneur          1521.            352 \n 4 housemaid             1392.            406 \n 5 management            1764.            572 \n 6 retired               1984.            787 \n 7 self-employed         1648.            526 \n 8 services               997.            340.\n 9 student               1388.            502 \n10 technician            1253.            421 \n11 unemployed            1522.            529 \n12 unknown               1772.            677 \n\n\n\n# Pregunta 9: Análisis de Contactos Anteriores\nsummary(bank_data$pdays)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   -1.0    -1.0    -1.0    40.2    -1.0   871.0 \n\nmean(bank_data$pdays[bank_data$y == \"yes\"], na.rm = TRUE)\n\n[1] 68.70297\n\n\n\n# Pregunta 10: Estudio General\n# Puedes utilizar técnicas de análisis más avanzadas como correlación, regresión, etc.\ncor(bank_data$balance, bank_data$duration, use = \"complete.obs\")\n\n[1] 0.02156038\n\nggplot(bank_data, aes(x = campaign, y = balance)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relación entre Campañas y Balance\",\n       x = \"Número de Campañas\",\n       y = \"Balance\") +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Cargar el conjunto de datos</span>"
    ]
  },
  {
    "objectID": "tema1_EDA2_solucion.html",
    "href": "tema1_EDA2_solucion.html",
    "title": "3  Ejercicio 1 (tidyr y dplyr)",
    "section": "",
    "text": "library(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n# A partir del siguiente dataframe realizar las siguientes operaciones de limpieza de datos:\nset.seed(1)\nstocks &lt;- data.frame(\n  time = as.Date('2009-01-01') + 0:9,\n  Walmart = rnorm(10, 20, 1),\n  Target = rnorm(10, 20, 2),\n  Walgreens = rnorm(10, 20, 4)\n)\n#       time  Walmart   Target Walgreens\n# 1  2009-01-01 19.37355 23.02356  23.67591\n# 2  2009-01-02 20.18364 20.77969  23.12855\n# 3  2009-01-03 19.16437 18.75752  20.29826\n# 4  2009-01-04 21.59528 15.57060  12.04259\n# 5  2009-01-05 20.32951 22.24986  22.47930\n# 6  2009-01-06 19.17953 19.91013  19.77549\n# 7  2009-01-07 20.48743 19.96762  19.37682\n# 8  2009-01-08 20.73832 21.88767  14.11699\n# 9  2009-01-09 20.57578 21.64244  18.08740\n# 10 2009-01-10 19.69461 21.18780  21.67177\n\n# Como se puede observar hay un problema de clave-valor en las compañias con sus observaciones.\n# Transformar los datos para que tengan una clave stock y el valor sea el precio. \n# Por lo tanto se requiere la funcion \"gather\".\n\n# Opcion 1:\nnew_stocks &lt;- gather(data = stocks, key = stock, value = price, Walmart, Target, Walgreens)\n\n# Opcion 2:\nnew_stocks &lt;- gather(data = stocks, key = stock, value = price, Walmart:Walgreens)\n\n# Opcion 3:\nnew_stocks &lt;- gather(data = stocks, key = stock, value = price, -time)\n# El último argumento, -time, significa que todas las columnas excepto el tiempo \n# contienen los pares clave-valor.\n\n\n# Devolver el dataframe al estado original utilizando la funcion \"spread\".\noriginal_stocks &lt;- spread(data = new_stocks, key = stock, value = price)\n\n# Utilizando el operador tuberia %&gt;% se desea realizar las siguientes operaciones anidadas.\n# 1) Transformar los datos para que tengan una clave stock y el valor sea \n# el precio mediante la funcion \"gather\".\n# 2) Agrupar los datos por la clave stock mediante la funcion \"group_by\".\n# 3) Obtener el precio minimo y maximo utilizando la funcion \"summarise\".\n\nstocks %&gt;% \n  gather(key = stock, value = price,Walmart:Walgreens)%&gt;% \n  group_by(stock) %&gt;% \n  summarise(min = min(price), max = max(price))\n\n# A tibble: 3 × 3\n  stock       min   max\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Target     15.6  23.0\n2 Walgreens  12.0  23.7\n3 Walmart    19.2  21.6\n\n###################################################################\n\n\n# Ejercicio 2 (dplyr)\n\nlibrary(dplyr)\nlibrary(nycflights13)\n\n# COMPROBACION.\n# Observamos los distintos dataframes que nos proporcionan.\n# Utilizamos el nombre del paquete y doblemente dos puntos (::) para comprobarlo.\n# Tambien se puede utilizar el nombre del dataframe si previamente estamos familiarizados.\n\n# PRIMERA OBSERVACION.\n# Comprobamos las variables de cada uno de los datasets que nos proporcionan\n# mediante la instrucción \"head\".\nprint(head(flights))\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nprint(head(airports))\n\n# A tibble: 6 × 8\n  faa   name                             lat   lon   alt    tz dst   tzone      \n  &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      \n1 04G   Lansdowne Airport               41.1 -80.6  1044    -5 A     America/Ne…\n2 06A   Moton Field Municipal Airport   32.5 -85.7   264    -6 A     America/Ch…\n3 06C   Schaumburg Regional             42.0 -88.1   801    -6 A     America/Ch…\n4 06N   Randall Airport                 41.4 -74.4   523    -5 A     America/Ne…\n5 09J   Jekyll Island Airport           31.1 -81.4    11    -5 A     America/Ne…\n6 0A9   Elizabethton Municipal Airport  36.4 -82.2  1593    -5 A     America/Ne…\n\nprint(head(weather))\n\n# A tibble: 6 × 15\n  origin  year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n  &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4         NA\n2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06        NA\n3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5         NA\n4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7         NA\n5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7         NA\n6 EWR     2013     1     1     6  37.9  28.0  67.2      240      11.5         NA\n# ℹ 4 more variables: precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;,\n#   time_hour &lt;dttm&gt;\n\nprint(head(airlines))\n\n# A tibble: 6 × 2\n  carrier name                    \n  &lt;chr&gt;   &lt;chr&gt;                   \n1 9E      Endeavor Air Inc.       \n2 AA      American Airlines Inc.  \n3 AS      Alaska Airlines Inc.    \n4 B6      JetBlue Airways         \n5 DL      Delta Air Lines Inc.    \n6 EV      ExpressJet Airlines Inc.\n\nprint(head(planes))\n\n# A tibble: 6 × 9\n  tailnum  year type               manufacturer model engines seats speed engine\n  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;              &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; \n1 N10156   2004 Fixed wing multi … EMBRAER      EMB-…       2    55    NA Turbo…\n2 N102UW   1998 Fixed wing multi … AIRBUS INDU… A320…       2   182    NA Turbo…\n3 N103US   1999 Fixed wing multi … AIRBUS INDU… A320…       2   182    NA Turbo…\n4 N104UW   1999 Fixed wing multi … AIRBUS INDU… A320…       2   182    NA Turbo…\n5 N10575   2002 Fixed wing multi … EMBRAER      EMB-…       2    55    NA Turbo…\n6 N105UW   1999 Fixed wing multi … AIRBUS INDU… A320…       2   182    NA Turbo…\n\n# Comprobamos las variables de cada uno de los datasets que nos proporcionan \n# mediante la instrucción \"summary\".\nprint(summary(flights))\n\n      year          month             day           dep_time    sched_dep_time\n Min.   :2013   Min.   : 1.000   Min.   : 1.00   Min.   :   1   Min.   : 106  \n 1st Qu.:2013   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 907   1st Qu.: 906  \n Median :2013   Median : 7.000   Median :16.00   Median :1401   Median :1359  \n Mean   :2013   Mean   : 6.549   Mean   :15.71   Mean   :1349   Mean   :1344  \n 3rd Qu.:2013   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:1744   3rd Qu.:1729  \n Max.   :2013   Max.   :12.000   Max.   :31.00   Max.   :2400   Max.   :2359  \n                                                 NA's   :8255                 \n   dep_delay          arr_time    sched_arr_time   arr_delay       \n Min.   : -43.00   Min.   :   1   Min.   :   1   Min.   : -86.000  \n 1st Qu.:  -5.00   1st Qu.:1104   1st Qu.:1124   1st Qu.: -17.000  \n Median :  -2.00   Median :1535   Median :1556   Median :  -5.000  \n Mean   :  12.64   Mean   :1502   Mean   :1536   Mean   :   6.895  \n 3rd Qu.:  11.00   3rd Qu.:1940   3rd Qu.:1945   3rd Qu.:  14.000  \n Max.   :1301.00   Max.   :2400   Max.   :2359   Max.   :1272.000  \n NA's   :8255      NA's   :8713                  NA's   :9430      \n   carrier              flight       tailnum             origin         \n Length:336776      Min.   :   1   Length:336776      Length:336776     \n Class :character   1st Qu.: 553   Class :character   Class :character  \n Mode  :character   Median :1496   Mode  :character   Mode  :character  \n                    Mean   :1972                                        \n                    3rd Qu.:3465                                        \n                    Max.   :8500                                        \n                                                                        \n     dest              air_time        distance         hour      \n Length:336776      Min.   : 20.0   Min.   :  17   Min.   : 1.00  \n Class :character   1st Qu.: 82.0   1st Qu.: 502   1st Qu.: 9.00  \n Mode  :character   Median :129.0   Median : 872   Median :13.00  \n                    Mean   :150.7   Mean   :1040   Mean   :13.18  \n                    3rd Qu.:192.0   3rd Qu.:1389   3rd Qu.:17.00  \n                    Max.   :695.0   Max.   :4983   Max.   :23.00  \n                    NA's   :9430                                  \n     minute        time_hour                     \n Min.   : 0.00   Min.   :2013-01-01 05:00:00.00  \n 1st Qu.: 8.00   1st Qu.:2013-04-04 13:00:00.00  \n Median :29.00   Median :2013-07-03 10:00:00.00  \n Mean   :26.23   Mean   :2013-07-03 05:22:54.64  \n 3rd Qu.:44.00   3rd Qu.:2013-10-01 07:00:00.00  \n Max.   :59.00   Max.   :2013-12-31 23:00:00.00  \n                                                 \n\nprint(summary(airports))\n\n     faa                name                lat             lon         \n Length:1458        Length:1458        Min.   :19.72   Min.   :-176.65  \n Class :character   Class :character   1st Qu.:34.26   1st Qu.:-119.19  \n Mode  :character   Mode  :character   Median :40.09   Median : -94.66  \n                                       Mean   :41.65   Mean   :-103.39  \n                                       3rd Qu.:45.07   3rd Qu.: -82.52  \n                                       Max.   :72.27   Max.   : 174.11  \n      alt                tz              dst               tzone          \n Min.   : -54.00   Min.   :-10.000   Length:1458        Length:1458       \n 1st Qu.:  70.25   1st Qu.: -8.000   Class :character   Class :character  \n Median : 473.00   Median : -6.000   Mode  :character   Mode  :character  \n Mean   :1001.42   Mean   : -6.519                                        \n 3rd Qu.:1062.50   3rd Qu.: -5.000                                        \n Max.   :9078.00   Max.   :  8.000                                        \n\nprint(summary(weather))\n\n    origin               year          month             day       \n Length:26115       Min.   :2013   Min.   : 1.000   Min.   : 1.00  \n Class :character   1st Qu.:2013   1st Qu.: 4.000   1st Qu.: 8.00  \n Mode  :character   Median :2013   Median : 7.000   Median :16.00  \n                    Mean   :2013   Mean   : 6.504   Mean   :15.68  \n                    3rd Qu.:2013   3rd Qu.: 9.000   3rd Qu.:23.00  \n                    Max.   :2013   Max.   :12.000   Max.   :31.00  \n                                                                   \n      hour            temp             dewp           humid       \n Min.   : 0.00   Min.   : 10.94   Min.   :-9.94   Min.   : 12.74  \n 1st Qu.: 6.00   1st Qu.: 39.92   1st Qu.:26.06   1st Qu.: 47.05  \n Median :11.00   Median : 55.40   Median :42.08   Median : 61.79  \n Mean   :11.49   Mean   : 55.26   Mean   :41.44   Mean   : 62.53  \n 3rd Qu.:17.00   3rd Qu.: 69.98   3rd Qu.:57.92   3rd Qu.: 78.79  \n Max.   :23.00   Max.   :100.04   Max.   :78.08   Max.   :100.00  \n                 NA's   :1        NA's   :1       NA's   :1       \n    wind_dir       wind_speed         wind_gust         precip        \n Min.   :  0.0   Min.   :   0.000   Min.   :16.11   Min.   :0.000000  \n 1st Qu.:120.0   1st Qu.:   6.905   1st Qu.:20.71   1st Qu.:0.000000  \n Median :220.0   Median :  10.357   Median :24.17   Median :0.000000  \n Mean   :199.8   Mean   :  10.518   Mean   :25.49   Mean   :0.004469  \n 3rd Qu.:290.0   3rd Qu.:  13.809   3rd Qu.:28.77   3rd Qu.:0.000000  \n Max.   :360.0   Max.   :1048.361   Max.   :66.75   Max.   :1.210000  \n NA's   :460     NA's   :4          NA's   :20778                     \n    pressure          visib          time_hour                    \n Min.   : 983.8   Min.   : 0.000   Min.   :2013-01-01 01:00:00.0  \n 1st Qu.:1012.9   1st Qu.:10.000   1st Qu.:2013-04-01 21:30:00.0  \n Median :1017.6   Median :10.000   Median :2013-07-01 14:00:00.0  \n Mean   :1017.9   Mean   : 9.255   Mean   :2013-07-01 18:26:37.7  \n 3rd Qu.:1023.0   3rd Qu.:10.000   3rd Qu.:2013-09-30 13:00:00.0  \n Max.   :1042.1   Max.   :10.000   Max.   :2013-12-30 18:00:00.0  \n NA's   :2729                                                     \n\nprint(summary(airlines))\n\n   carrier              name          \n Length:16          Length:16         \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nprint(summary(planes))\n\n   tailnum               year          type           manufacturer      \n Length:3322        Min.   :1956   Length:3322        Length:3322       \n Class :character   1st Qu.:1997   Class :character   Class :character  \n Mode  :character   Median :2001   Mode  :character   Mode  :character  \n                    Mean   :2000                                        \n                    3rd Qu.:2005                                        \n                    Max.   :2013                                        \n                    NA's   :70                                          \n    model              engines          seats           speed      \n Length:3322        Min.   :1.000   Min.   :  2.0   Min.   : 90.0  \n Class :character   1st Qu.:2.000   1st Qu.:140.0   1st Qu.:107.5  \n Mode  :character   Median :2.000   Median :149.0   Median :162.0  \n                    Mean   :1.995   Mean   :154.3   Mean   :236.8  \n                    3rd Qu.:2.000   3rd Qu.:182.0   3rd Qu.:432.0  \n                    Max.   :4.000   Max.   :450.0   Max.   :432.0  \n                                                    NA's   :3299   \n    engine         \n Length:3322       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\n\n# Simplificar los dataframes originales a 100 observaciones. Renombrarlos\n# introduciendo la coletilla \"_simple\".\n\nflights_simple &lt;- head(flights,100)\nairports_simple &lt;- head(airports,100)\nweather_simple &lt;- head(weather,100)\nairlines_simple &lt;- head(airlines,100)\nplanes_simple &lt;- head(planes,100)\n\n\n# Selecciona los tipos de aerolinea (\"carrier\") mediante la instruccion \"select\" \n# y el operador \"unique\" concatenados con el operador tuberia %&gt;%.\nairlines_simple %&gt;% unique %&gt;% select(carrier)\n\n# A tibble: 16 × 1\n   carrier\n   &lt;chr&gt;  \n 1 9E     \n 2 AA     \n 3 AS     \n 4 B6     \n 5 DL     \n 6 EV     \n 7 F9     \n 8 FL     \n 9 HA     \n10 MQ     \n11 OO     \n12 UA     \n13 US     \n14 VX     \n15 WN     \n16 YV     \n\n\n\n# Obtener la media y el maximo de asientos (\"seats\") que tienen los aviones. \n# Utilizar el operador tuberia %&gt;%.\nplanes_simple %&gt;% summarise(mean = mean(seats),max_engines = max(seats))\n\n# A tibble: 1 × 2\n   mean max_engines\n  &lt;dbl&gt;       &lt;int&gt;\n1  105.         330\n\n\n\n# Ordenar los aviones por numero de motores (\"engines\") y numero de asientos (\"seats\").\nresult1 &lt;- arrange(planes_simple,engines,seats)\nprint(result1)\n\n# A tibble: 100 × 9\n   tailnum  year type              manufacturer model engines seats speed engine\n   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; \n 1 N10156   2004 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 2 N10575   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 3 N11106   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 4 N11107   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 5 N11109   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 6 N11113   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 7 N11119   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 8 N11121   2003 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 9 N11127   2003 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n10 N11137   2003 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n# ℹ 90 more rows\n\n\n\n# Averigua que numero de cola comparten los dataframes \"flights_simple\" \n# y \"planes_simple\" que has creado anteriormente.\n# Obten su aerolinea (\"carrier\")\nshared &lt;- inner_join(flights_simple,planes_simple,by=\"tailnum\") # -&gt; N14228\nshared_carrier &lt;- shared$carrier\nprint(shared_carrier)\n\n[1] \"EV\"\n\n\n\n# Cruzar los datos de vuelos (\"flights\") con los aviones (\"planes\") \n# por el numero de cola (\"tailnum\") que no coincidan.\n# De esos obtener aquellos con 2 o mas motores.\n# Finlmente obtener los distintos modelos de avión que satisfacen las premisas anteriores.\nfp &lt;- anti_join(planes_simple,flights_simple,by=\"tailnum\")\nengines_fp &lt;- filter(fp,engines &gt;= 2)\nresult2 &lt;- unique(engines_fp$model) # No queremos los repetidos. Por lo tanto usamos \"unique\".\nprint(result2)\n\n[1] \"EMB-145XR\" \"A320-214\"  \"EMB-145LR\" \"737-824\"   \"767-332\"   \"757-224\"  \n\n\n\n# Crea una nueva variable que calcule el retraso total sumando los\n# delays acumulados (\"dep_delay\") y (\"arr_delay\").\n# Almacena el dataframe resultante en \"flights_total\".\nflights_total &lt;- mutate(flights_simple,total_delay=dep_delay+arr_delay)\n\n# En base a la variable anteriormente obtenida, devuelve los aviones que \n# han llegado con antelación a su destino.\nfilter(flights_total,total_delay &lt; 0)\n\n# A tibble: 57 × 20\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      544            545        -1     1004           1022\n 2  2013     1     1      554            600        -6      812            837\n 3  2013     1     1      557            600        -3      709            723\n 4  2013     1     1      557            600        -3      838            846\n 5  2013     1     1      558            600        -2      849            851\n 6  2013     1     1      558            600        -2      853            856\n 7  2013     1     1      558            600        -2      923            937\n 8  2013     1     1      559            559         0      702            706\n 9  2013     1     1      559            600        -1      854            902\n10  2013     1     1      600            600         0      851            858\n# ℹ 47 more rows\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, total_delay &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ejercicio 1 (tidyr y dplyr)</span>"
    ]
  }
]